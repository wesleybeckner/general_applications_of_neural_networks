
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.1">
    
    
      
        <title>Computer Vision I - General Applications of Neural Networks</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.23b6d78a.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.e6a45f82.min.css">
        
          
          
          <meta name="theme-color" content="#2094f3">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
      <link rel="stylesheet" href="../styles.css">
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-114664473-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script>
  <script async src="https://www.google-analytics.com/analytics.js"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="blue" data-md-color-accent="indigo">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#general-applications-of-neural-networks-session-3-computer-vision-part-1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="General Applications of Neural Networks" class="md-header__button md-logo" aria-label="General Applications of Neural Networks" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            General Applications of Neural Networks
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Computer Vision I
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="General Applications of Neural Networks" class="md-nav__button md-logo" aria-label="General Applications of Neural Networks" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    General Applications of Neural Networks
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../about/" class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Sessions
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Sessions" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Sessions
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S1_Multilayer_Perceptron/" class="md-nav__link">
        The Multilayer Perceptron
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S2_Feed_Forward_Neural_Networks/" class="md-nav__link">
        Feed Forward Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Computer Vision I
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Computer Vision I
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#30-preparing-environment-and-importing-data" class="md-nav__link">
    3.0 Preparing Environment and Importing Data
  </a>
  
    <nav class="md-nav" aria-label="3.0 Preparing Environment and Importing Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#301-import-packages" class="md-nav__link">
    3.0.1 Import Packages
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#302-load-dataset-segway-into-images" class="md-nav__link">
    3.0.2 Load Dataset + Segway Into Images
  </a>
  
    <nav class="md-nav" aria-label="3.0.2 Load Dataset + Segway Into Images">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise-1-loading-images" class="md-nav__link">
    🏋️ Exercise 1: Loading Images
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#31-the-classifier-structure" class="md-nav__link">
    3.1 The Classifier Structure
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#32-convolutions-relu-and-maximum-pooling" class="md-nav__link">
    3.2 Convolutions, ReLU and Maximum Pooling
  </a>
  
    <nav class="md-nav" aria-label="3.2 Convolutions, ReLU and Maximum Pooling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#321-the-convolution" class="md-nav__link">
    3.2.1 The Convolution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#322-activations" class="md-nav__link">
    3.2.2 Activations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#323-relu" class="md-nav__link">
    3.2.3 ReLU
  </a>
  
    <nav class="md-nav" aria-label="3.2.3 ReLU">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise-2-experiment-with-kernels" class="md-nav__link">
    🏋️ Exercise 2: Experiment with Kernels
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#324-condense-with-maximum-pooling" class="md-nav__link">
    3.2.4 Condense with Maximum Pooling
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#33-enrichment-practice-with-global-average-pooling" class="md-nav__link">
    3.3 Enrichment: Practice with Global Average Pooling
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S4_Computer_Vision_II/" class="md-nav__link">
        Computer Vision II
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../S5_Time_Series_Analysis/" class="md-nav__link">
        Time Series Analysis
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Exercises
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Exercises" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Exercises
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../exercises/E1_Neural_Network_Linearity/" class="md-nav__link">
        Neural Network Linearity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../exercises/E4_Testing_and_Serving_Code/" class="md-nav__link">
        Testing and Serving Code
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#30-preparing-environment-and-importing-data" class="md-nav__link">
    3.0 Preparing Environment and Importing Data
  </a>
  
    <nav class="md-nav" aria-label="3.0 Preparing Environment and Importing Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#301-import-packages" class="md-nav__link">
    3.0.1 Import Packages
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#302-load-dataset-segway-into-images" class="md-nav__link">
    3.0.2 Load Dataset + Segway Into Images
  </a>
  
    <nav class="md-nav" aria-label="3.0.2 Load Dataset + Segway Into Images">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise-1-loading-images" class="md-nav__link">
    🏋️ Exercise 1: Loading Images
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#31-the-classifier-structure" class="md-nav__link">
    3.1 The Classifier Structure
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#32-convolutions-relu-and-maximum-pooling" class="md-nav__link">
    3.2 Convolutions, ReLU and Maximum Pooling
  </a>
  
    <nav class="md-nav" aria-label="3.2 Convolutions, ReLU and Maximum Pooling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#321-the-convolution" class="md-nav__link">
    3.2.1 The Convolution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#322-activations" class="md-nav__link">
    3.2.2 Activations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#323-relu" class="md-nav__link">
    3.2.3 ReLU
  </a>
  
    <nav class="md-nav" aria-label="3.2.3 ReLU">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise-2-experiment-with-kernels" class="md-nav__link">
    🏋️ Exercise 2: Experiment with Kernels
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#324-condense-with-maximum-pooling" class="md-nav__link">
    3.2.4 Condense with Maximum Pooling
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#33-enrichment-practice-with-global-average-pooling" class="md-nav__link">
    3.3 Enrichment: Practice with Global Average Pooling
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                

<p><a href="https://colab.research.google.com/github/wesleybeckner/general_applications_of_neural_networks/blob/main/notebooks/S3_Computer_Vision_I.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<h1 id="general-applications-of-neural-networks-session-3-computer-vision-part-1">General Applications of Neural Networks <br> Session 3: Computer Vision Part 1<a class="headerlink" href="#general-applications-of-neural-networks-session-3-computer-vision-part-1" title="Permanent link">&para;</a></h1>
<p><strong>Instructor</strong>: Wesley Beckner</p>
<p><strong>Contact</strong>: <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#119;&#101;&#115;&#108;&#101;&#121;&#98;&#101;&#99;&#107;&#110;&#101;&#114;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;">&#119;&#101;&#115;&#108;&#101;&#121;&#98;&#101;&#99;&#107;&#110;&#101;&#114;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a></p>
<hr />
<p><br></p>
<p>In this session we will turn our magnifying glass over to images. There are many application-centric subdomains of machine learning and this is one of them (another would be natural language processing). We can use the power of image related machine learning to replace, augment, or optimize what would typically be reserved for a humans. </p>
<p>In this session we will:</p>
<ul>
<li>Use modern deep-learning networks using keras</li>
<li>Design CNNs</li>
<li>Learn about feature extraction in convolutional layers</li>
<li>Learn about transfer learning</li>
<li>Utilize data augmentation in the context of images</li>
</ul>
<p><br></p>
<p><em>images in this notebook borrowed from <a href="https://mathformachines.com/">Ryan Holbrook</a></em></p>
<hr />
<p><br></p>
<p><a name='top'></a></p>
<p><a name='x.0'></a></p>
<h2 id="30-preparing-environment-and-importing-data">3.0 Preparing Environment and Importing Data<a class="headerlink" href="#30-preparing-environment-and-importing-data" title="Permanent link">&para;</a></h2>
<p><a href="#top">back to top</a></p>
<p><a name='x.0.1'></a></p>
<h3 id="301-import-packages">3.0.1 Import Packages<a class="headerlink" href="#301-import-packages" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">EarlyStopping</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">image_dataset_from_directory</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="k">def</span> <span class="nf">show_kernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">text_size</span><span class="o">=</span><span class="mi">28</span><span class="p">):</span>
    <span class="c1"># helper function borrowed from Ryan Holbrock</span>
    <span class="c1"># Format kernel</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">digits</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">digits</span><span class="p">)</span>

    <span class="c1"># Plot kernel</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;Blues_r&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">thresh</span> <span class="o">=</span> <span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="n">kernel</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="mi">2</span>
    <span class="c1"># Optionally, add value labels</span>
    <span class="k">if</span> <span class="n">label</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">rows</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="n">cols</span><span class="p">)):</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">color</span> <span class="o">=</span> <span class="n">cmap</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">val</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="n">cmap</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> 
                     <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">text_size</span><span class="p">,</span>
                     <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
</code></pre></div>

<p><a name='x.0.2'></a></p>
<h3 id="302-load-dataset-segway-into-images">3.0.2 Load Dataset + Segway Into Images<a class="headerlink" href="#302-load-dataset-segway-into-images" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<p>We're going to be working with a new kind of data structure today, <em>an image</em>. There are <a href="https://towardsdatascience.com/what-library-can-load-image-in-python-and-what-are-their-difference-d1628c6623ad">many ways</a> to load images into python: <em>matplotlib (<code>plt.imread()</code>), OpenCV (<code>cv2.imread()</code>), Pillow (<code>Image.open()</code>), scikit-image (<code>io.imread()</code>), tensorflow (<code>tf.io.read_file()</code> and <code>tf.io.decode_jpeg()</code>)</em>.</p>
<p>Let's give these a shot!</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Sync your google drive folder</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s2">&quot;/content/drive&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>Mounted at /content/drive
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># image read libraries</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 
<span class="kn">import</span> <span class="nn">skimage</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span>

<span class="c1">### YOU WILL CHANGE TO THE PATH WHERE YOU HAVE TECH_FUNDAMENTALS ###</span>
<span class="n">path_to_casting_data</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/courses/TECH_FUNDAMENTALS/data/casting_data_class_practice&#39;</span>
<span class="n">technocast_train_path</span> <span class="o">=</span> <span class="n">path_to_casting_data</span> <span class="o">+</span> <span class="s1">&#39;/train/&#39;</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="n">technocast_train_path</span> <span class="o">+</span> <span class="s1">&#39;/ok_front/cast_ok_0_1.jpeg&#39;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># pyplot</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">img1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">img1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">img1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;class &#39;numpy.ndarray&#39;&gt;
(300, 300, 3)





(-0.5, 299.5, 299.5, -0.5)
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_8_2.png" /></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># cv2</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="n">img2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">img2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">img2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;class &#39;numpy.ndarray&#39;&gt;
(300, 300, 3)





(-0.5, 299.5, 299.5, -0.5)
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_9_2.png" /></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># PIL</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">img3</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">img3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img3</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#conv to array</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;class &#39;PIL.JpegImagePlugin.JpegImageFile&#39;&gt;
(300, 300, 3)





(-0.5, 299.5, 299.5, -0.5)
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_10_2.png" /></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># skimage</span>
<span class="kn">import</span> <span class="nn">skimage</span>
<span class="n">img4</span> <span class="o">=</span> <span class="n">skimage</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">img4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">img4</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;class &#39;numpy.ndarray&#39;&gt;
(300, 300, 3)





(-0.5, 299.5, 299.5, -0.5)
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_11_2.png" /></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tensorflow</span>
<span class="n">img5</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
<span class="n">img5</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">decode_jpeg</span><span class="p">(</span><span class="n">img5</span><span class="p">)</span>

<span class="c1"># conver to bw</span>
<span class="n">img5</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">rgb_to_grayscale</span><span class="p">(</span><span class="n">img5</span><span class="p">)</span>

<span class="c1"># optionally could convert to an array</span>
<span class="c1"># img5 = np.asarray(img5)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">img5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">img5</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># drop the extra channel (3d squeezed into 2d, rgb to intensity/gray)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">img5</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">img5</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">255</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>&lt;class &#39;tensorflow.python.framework.ops.EagerTensor&#39;&gt;
(300, 300, 1)
(300, 300)





(-0.5, 299.5, 299.5, -0.5)
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_12_2.png" /></p>
<h4 id="exercise-1-loading-images">🏋️ Exercise 1: Loading Images<a class="headerlink" href="#exercise-1-loading-images" title="Permanent link">&para;</a></h4>
<p>Find 2 different images on the internet (any 2 of: jpg, png, and svg format). Load them into python as</p>
<ol>
<li>colored, and then also convert to</li>
<li>grayscale</li>
</ol>
<p>using tensorflow and pyplot. Convert to grayscale using <code>tf.image.rgb_to_grayscale</code> for one of the images and <code>np.dot()</code> for the other.</p>
<div class="codehilite"><pre><span></span><code><span class="n">img_path2</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/MyDrive/courses/TECH_FUNDAMENTALS/data/squirtle.png&quot;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># tensorflow</span>

<span class="c1">### YOUR CODE HERE ###</span>
<span class="c1">#&lt;my_var&gt; = tf.io.read_file(&lt;path_to_file&gt;)</span>
<span class="c1">#&lt;my_var&gt; = tf.io.decode_jpeg(&lt;my_var)</span>

<span class="c1"># extra channel (alpha channel for opacity, sometimes)</span>
<span class="c1">#&lt;my_var&gt; = tf.image.rgb_to_grayscale(&lt;my_var&gt;[indexed_at_rgb_values])</span>

<span class="c1"># plt.imshow(tf.squeeze(my_var_so_that_it_is_reduced_to_one_chanel), cmap=&#39;some_scheme&#39;)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">img_path3</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/MyDrive/courses/TECH_FUNDAMENTALS/data/ghastly.jpg&quot;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># pyplot</span>

<span class="c1">### YOUR CODE HERE ###</span>
<span class="c1"># &lt;my_var&gt; = plt.imread(&lt;path_to_file&gt;)</span>

<span class="c1"># extra channel (alpha channel for opacity, sometimes)</span>

<span class="c1"># &lt;my_var&gt; = np.dot(&lt;my_var&gt;[indexed_at_rgb_values], rgb_weights)</span>

<span class="c1"># plt.imshow(&lt;my_var&gt;, cmap=&#39;some_scheme&#39;)</span>
</code></pre></div>

<h2 id="31-the-classifier-structure">3.1 The Classifier Structure<a class="headerlink" href="#31-the-classifier-structure" title="Permanent link">&para;</a></h2>
<p>Convolutional neural networks (CNNs, Convnets) take the gold for machine vision. We'll talk about what convolutional layers are in a moment. For now lets talk about the general structure of these types of neural networks.</p>
<p>A CNN consists of a <strong><em>base</em></strong> and a <strong><em>head</em></strong>. </p>
<p align=center>
<img src="https://raw.githubusercontent.com/wesleybeckner/general_applications_of_neural_networks/main/assets/U0n5xjU.png" width=600></img>
</p>

<p>The base is used to extract the relevant features from the image. It consits mainly of convolutional layers. The head is used to map those features to the classification task and mostly consits of dense layers. </p>
<p>What is a visual feature? It is a relevant abstraction from the image data, often edges and shapes, that then form more abstract objects like eyes, ears or wheels and windows:</p>
<p align=center>
<img src="https://raw.githubusercontent.com/wesleybeckner/general_applications_of_neural_networks/main/assets/UUAafkn.png" width=600></img>
</p>
<p><small> note: this is an oversimplification but it gives the general idea. </small></p>
<p>A classification NN will always have this phenomenon where, early in the network layers are learning features, and later in the network layers are appropriating those features to different classes. In a CNN this phenomenon is accentuated by the base-head dynamic. Given that the feature generation task can be very similar across images, often we use the base of a <strong><em>pretrained</em></strong> model. This strategy is called <strong><em>transfer learning</em></strong> and is extraordinarily powerful when dealing with small datasets!</p>
<blockquote>
<p>"When doing transfer learning, it's generally not a good idea to retrain the entire base -- at least not without some care. The reason is that the random weights in the head will initially create large gradient updates, which propogate back into the base layers and destroy much of the pretraining. Using techniques known as fine tuning it's possible to further train the base on new data, but this requires some care to do well." -kaggle gurus</p>
</blockquote>
<p align=center>
<img src="https://raw.githubusercontent.com/wesleybeckner/general_applications_of_neural_networks/main/assets/E49fsmV.png" width=600></img>
</p>

<p><a name='x.2'></a></p>
<h2 id="32-convolutions-relu-and-maximum-pooling">3.2 Convolutions, ReLU and Maximum Pooling<a class="headerlink" href="#32-convolutions-relu-and-maximum-pooling" title="Permanent link">&para;</a></h2>
<p><a href="#top">back to top</a></p>
<p>We'll now discuss the three heavy-weights for convolutional networks: convolutions, rectified linear units, and maximum pooling. You can think of these as the agents of three primary steps in a convolutional network:</p>
<ol>
<li>Filter an image down to features (convolution)</li>
<li>Detect that the feature is present (ReLU)</li>
<li>Condense the image to enhance the features (maximum pooling)</li>
</ol>
<p>These three steps are demonstrated in the following image:</p>
<p align=center>
<img src="https://raw.githubusercontent.com/wesleybeckner/general_applications_of_neural_networks/main/assets/IYO9lqp.jpeg" width=600></img>
</p>

<p><a name='x.2.1'></a></p>
<h3 id="321-the-convolution">3.2.1 The Convolution<a class="headerlink" href="#321-the-convolution" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<p>The convolutional layer carries out the filtering step. We can create a convolution in keras like so:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="c1"># activation is None</span>
    <span class="c1"># More layers follow</span>
<span class="p">])</span>
</code></pre></div>

<p>Let's talk about the hyperparameters in <code>Conv2D</code>.</p>
<p>The weights a CNN learns are primarily in its <strong><em>kernels</em></strong>. The kernels are a collection of arrays that are passed over the image to produce weighted sums. An example of a 3x3 kernel:</p>
<p align=center>
<img src="https://raw.githubusercontent.com/wesleybeckner/general_applications_of_neural_networks/main/assets/uJfD9r9.png" width=200></img>
</p>

<p>As the kernel is swept over the image, it acts to accentuate certain features. For instance, some kernels will bring out vertical edges, some horizontal edges, others will accentuate gradients in a general sense. </p>
<p align=center>
<img src="https://raw.githubusercontent.com/wesleybeckner/general_applications_of_neural_networks/main/assets/j3lk26U.png" width=300></img>
</p>

<p>As we train our CNN, it learns what kernels are best for learning relevant features for the classification task. We set the number of kernels with the <code>filters</code> hyperparameter and the shape with <code>kernel_size</code>. The shape will usually be an odd number so that the kernel is oriented around one center pixel, but this is not a requirement.  </p>
<p><a name='x.2.2'></a></p>
<h3 id="322-activations">3.2.2 Activations<a class="headerlink" href="#322-activations" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<p>The <strong><em>activations</em></strong> also called <strong><em>feature maps</em></strong> are the output from the kernels. We can see an example:</p>
<p align=center>
<img src="https://raw.githubusercontent.com/wesleybeckner/general_applications_of_neural_networks/main/assets/JxBwchH.png" width=800></img>
</p>

<p>Notice that the left and middle kernels are augmenting horizontal boundaries.</p>
<p><a name='x.2.3'></a></p>
<h3 id="323-relu">3.2.3 ReLU<a class="headerlink" href="#323-relu" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<p>The ReLU should be familiar by now. It appears here in CNNs to further isolate the presense of features in the feature maps. Remember that it sets anything below 0 to simply 0. In a way it is saying, anything that is unimportant, is equally unimportant. Let's see it in action:</p>
<p align=center>
<img src="https://raw.githubusercontent.com/wesleybeckner/general_applications_of_neural_networks/main/assets/dKtwzPY.png" width=800></img>
</p>

<p>And, just as with dense layers, the ReLU allows us to create non-linear relationships within our network, something that we definitely want. </p>
<p><a name='x.2.4'></a></p>
<h4 id="exercise-2-experiment-with-kernels">🏋️ Exercise 2: Experiment with Kernels<a class="headerlink" href="#exercise-2-experiment-with-kernels" title="Permanent link">&para;</a></h4>
<p><a href="#top">back to top</a></p>
<div class="codehilite"><pre><span></span><code><span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">decode_jpeg</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_26_0.png" /></p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">kernel</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span>
    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
<span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">show_kernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_27_0.png" /></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Reformat for batch compatibility.</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">rgb_to_grayscale</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">convert_image_dtype</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Prep the kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="p">[</span><span class="o">*</span><span class="n">kernel</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">image_filter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
    <span class="nb">input</span><span class="o">=</span><span class="n">image</span><span class="p">,</span>
    <span class="n">filters</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
    <span class="c1"># we&#39;ll talk about strides and padding in the next session</span>
    <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image_filter</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_29_0.png" /></p>
<p>And now the ReLU step:</p>
<div class="codehilite"><pre><span></span><code><span class="n">image_detect</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">image_filter</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image_detect</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_31_0.png" /></p>
<p>We're going to wrap these steps into a function and simply play around with the kernel to see how it changes the feature mapping for this impellar.</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">apply_the_KERN</span><span class="p">(</span><span class="n">kernel</span><span class="p">):</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

  <span class="n">image_path</span> <span class="o">=</span> <span class="n">technocast_train_path</span> <span class="o">+</span> <span class="s1">&#39;/ok_front/cast_ok_0_1.jpeg&#39;</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">decode_jpeg</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>


  <span class="c1"># Reformat for batch compatibility.</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">rgb_to_grayscale</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">convert_image_dtype</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">kernel</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="p">[</span><span class="o">*</span><span class="n">kernel</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
  <span class="n">kernel</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

  <span class="n">image_filter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
      <span class="nb">input</span><span class="o">=</span><span class="n">image</span><span class="p">,</span>
      <span class="n">filters</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
      <span class="c1"># we&#39;ll talk about strides and padding in the next session</span>
      <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
      <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

  <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image_filter</span><span class="p">))</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
  <span class="n">image_detect</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">image_filter</span><span class="p">)</span>

  <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image_detect</span><span class="p">))</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</code></pre></div>

<p>For this exercise create 2-3 kernels and show how they accentuate different features:</p>
<div class="codehilite"><pre><span></span><code><span class="n">kernel</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span>
  <span class="c1">### YOUR KERNEL HERE ###</span>
  <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
  <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
  <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
<span class="p">])</span>
<span class="n">show_kernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>

<span class="n">apply_the_KERN</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_35_0.png" /></p>
<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_35_1.png" /></p>
<blockquote>
<p>notice anything with different patterns? What happens when the sum of the kernel is more than 0? more than 1?</p>
</blockquote>
<p><a name='x.2.5'></a></p>
<h3 id="324-condense-with-maximum-pooling">3.2.4 Condense with Maximum Pooling<a class="headerlink" href="#324-condense-with-maximum-pooling" title="Permanent link">&para;</a></h3>
<p><a href="#top">back to top</a></p>
<p>In this last step that we'll cover, we're going to condense the image in a way that accentuates the identified features. This is done with <code>MaxPool2D</code> layer in keras</p>
<p>A <code>MaxPool2D</code> layer isn't much different from a <code>Conv2D</code> layer other than that, instead of taking a sum, the kernel (not really a kernel) just returns the maximum value. <code>kernel_size</code> is replaced with <code>pool_size</code> and there are no trainable weights (hence not a kernel).</p>
<p align=center>
<img src="https://raw.githubusercontent.com/wesleybeckner/general_applications_of_neural_networks/main/assets/hK5U2cd.png" width=400></img>
</p>
<p>Features are indeed intensified by the max pooling, but another way to think of this is that carrying all those empty "black" pixels through the network is computationally expensive without adding much information. Max pooling is a quick and dirty way of consolidating the network and retaining only the most salient information.</p>
<div class="codehilite"><pre><span></span><code><span class="n">image_condense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span>
    <span class="nb">input</span><span class="o">=</span><span class="n">image_detect</span><span class="p">,</span> <span class="c1"># image in the Detect step above</span>
    <span class="n">window_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">pooling_type</span><span class="o">=</span><span class="s1">&#39;MAX&#39;</span><span class="p">,</span>
    <span class="c1"># we&#39;ll talk about strides and padding in the next session</span>
    <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image_condense</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div>

<p><img alt="png" src="../S3_Computer_Vision_I_files/S3_Computer_Vision_I_39_0.png" /></p>
<p><a name='x.3'></a></p>
<h2 id="33-enrichment-practice-with-global-average-pooling">3.3 Enrichment: Practice with Global Average Pooling<a class="headerlink" href="#33-enrichment-practice-with-global-average-pooling" title="Permanent link">&para;</a></h2>
<p><a href="#top">back to top</a></p>
<p>Usually at the end of the convolutional blocks, we use a <code>Flatten()</code> layer to convert the 2D arrays of feature maps to 1D to feed into the Dense layers of the network. Another method that has become popular is to use <strong><em>Global Average Pooling</em></strong>. With this schematic, each feature map is turned into an average. By this method, the head of the CNN now only has to make a classificaiton based on how <em>turned on</em> the feature maps are, indicated by the result of the global average pooling. We would implement this with keras like so:</p>
<div class="codehilite"><pre><span></span><code>model = keras.Sequential([
    pretrained_base,
    layers.GlobalAvgPool2D(),
    layers.Dense(1, activation=&#39;sigmoid&#39;),
])
</code></pre></div>

<h1 id="resources">Resources<a class="headerlink" href="#resources" title="Permanent link">&para;</a></h1>
<p><a href="https://poloclub.github.io/cnn-explainer/#article-convolution">CNN Explainer</a></p>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../S2_Feed_Forward_Neural_Networks/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Feed Forward Neural Networks" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Feed Forward Neural Networks
            </div>
          </div>
        </a>
      
      
        
        <a href="../S4_Computer_Vision_II/" class="md-footer__link md-footer__link--next" aria-label="Next: Computer Vision II" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Computer Vision II
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.c7dec7e7.min.js"}</script>
    
    
      <script src="../assets/javascripts/bundle.da79ceb7.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  </body>
</html>